{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from numpy.random import seed\n",
    "from tensorflow import set_random_seed\n",
    "from time import strftime\n",
    "from PIL import Image\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "from keras.datasets import mnist\n",
    "from matplotlib import pyplot\n",
    "\n",
    "## Seed for testing\n",
    "seed(888)\n",
    "set_random_seed(404)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "(x_train_data, y_train_data), (x_test_data, y_test_data) = mnist.load_data()\n",
    "\n",
    "# Local Data Paths\n",
    "LOGGING_PATH = 'tensorboard_mnist_digit_logs/'\n",
    "\n",
    "# Global parameters\n",
    "VALIDATION_SIZE = 10000\n",
    "IM_WIDTH = x_train_data.shape[1]\n",
    "IM_HEIGHT = x_train_data.shape[2]\n",
    "IM_CHANNELS = 1\n",
    "MNIST_INPUT = IM_WIDTH * IM_HEIGHT * IM_CHANNELS\n",
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: X=(60000, 784), y=(60000,)\n",
      "Test:  X=(10000, 784), y=(10000,)\n"
     ]
    }
   ],
   "source": [
    "# plot first few images\n",
    "for i in range(9):\n",
    "    # define subplot\n",
    "    pyplot.subplot(330 + 1 + i)\n",
    "    # plot raw pixel data\n",
    "    pyplot.imshow(x_train_data[i], cmap=pyplot.get_cmap('gray'))\n",
    "\n",
    "# show the figure\n",
    "pyplot.show()\n",
    "\n",
    "# Flatten our input images.\n",
    "x_train_data = x_train_data.reshape((x_train_data.shape[0], IM_WIDTH * IM_HEIGHT))\n",
    "x_test_data  = x_test_data.reshape((x_test_data.shape[0], IM_WIDTH * IM_HEIGHT))\n",
    "\n",
    "# summarize loaded dataset\n",
    "print('Train: X=%s, y=%s' % (x_train_data.shape, y_train_data.shape))\n",
    "print('Test:  X=%s, y=%s' % (x_test_data.shape, y_test_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize our data\n",
    "x_train_data, x_test_data = x_train_data / 255.0 , x_test_data / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expand output shapes into one-hot format for testing and training labels\n",
    "y_train_data = np.eye(NUM_CLASSES)[y_train_data]\n",
    "y_test_data  = np.eye(NUM_CLASSES)[y_test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784) (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Generate Validation sets\n",
    "x_validate = x_train_data[:VALIDATION_SIZE]\n",
    "y_validate = y_train_data[:VALIDATION_SIZE]\n",
    "\n",
    "# Update our training sets\n",
    "x_train_data = x_train_data[VALIDATION_SIZE:]\n",
    "y_train_data = y_train_data[VALIDATION_SIZE:]\n",
    "\n",
    "print(x_train_data.shape, x_validate.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw inputs of our feature vectors\n",
    "X = tf.placeholder(tf.float32, shape=[None, MNIST_INPUT], name='X') #MNIST digits are stored in a flattened 28 x 28 x 1 image vector\n",
    "Y = tf.placeholder(tf.float32, shape=[None, NUM_CLASSES], name='labels') #MNIST digits follow 10 classes, 0 to 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_epochs = 50\n",
    "lr = 0.0001\n",
    "\n",
    "# Neural Network Architecture\n",
    "num_hidden1 = 512\n",
    "num_hidden2 = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_layer(input, weight_dim, bias_dim, name):\n",
    "    \n",
    "    with tf.name_scope(name):\n",
    "        initial_w = tf.truncated_normal(shape=weight_dim, stddev=0.1, seed=42)\n",
    "        w = tf.Variable(initial_value=initial_w, name='W')\n",
    "\n",
    "        initial_b = tf.constant(value=0.0, shape=bias_dim)\n",
    "        b = tf.Variable(initial_value=initial_b, name='B')\n",
    "\n",
    "        layer_in = tf.matmul(input, w) + b\n",
    "        \n",
    "        if name=='out':\n",
    "            layer_out = tf.nn.softmax(layer_in)\n",
    "        else:\n",
    "            layer_out = tf.nn.relu(layer_in)\n",
    "        \n",
    "        tf.summary.histogram('weights', w)\n",
    "        tf.summary.histogram('biases', b)\n",
    "        \n",
    "        return layer_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-17-080dc3c4ed68>:4: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "layer_1 = setup_layer(X, weight_dim=[MNIST_INPUT, num_hidden1], \n",
    "                      bias_dim=[num_hidden1], name='layer_1')\n",
    "\n",
    "layer_drop = tf.nn.dropout(layer_1, keep_prob=0.8, name='dropout_layer')\n",
    "\n",
    "layer_2 = setup_layer(layer_drop, weight_dim=[num_hidden1, num_hidden2], \n",
    "                      bias_dim=[num_hidden2], name='layer_2')\n",
    "\n",
    "output = setup_layer(layer_2, weight_dim=[num_hidden2, NUM_CLASSES], \n",
    "                      bias_dim=[NUM_CLASSES], name='out')\n",
    "\n",
    "model_name = f'{num_hidden1}-DO-{num_hidden2} LR{lr} E{num_epochs}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created directories!\n"
     ]
    }
   ],
   "source": [
    "# Folder for Tensorboard\n",
    "\n",
    "folder_name = f'{model_name} at {strftime(\"%H:%M\")}'\n",
    "folder_name = folder_name.replace('.', '')\n",
    "folder_name = folder_name.replace(':', '')\n",
    "directory = os.path.join(LOGGING_PATH, folder_name)\n",
    "\n",
    "try:\n",
    "    os.makedirs(directory)\n",
    "except OSError as exception:\n",
    "    print(exception.strerror)\n",
    "else:\n",
    "    print('Successfully created directories!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss, Optimization and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are doing batch training, need to aggregate the means\n",
    "with tf.name_scope('loss_calc'):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=output))\n",
    "\n",
    "# Optimization definition\n",
    "with tf.name_scope('optimizer'):\n",
    "    optimizer = tf.train.AdamOptimizer(lr)\n",
    "    train_step = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy Metric\n",
    "with tf.name_scope('accuracy_calc'):\n",
    "    correct_pred = tf.equal(tf.argmax(output, axis=1), tf.argmax(Y, axis=1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "    \n",
    "with tf.name_scope('performance'):\n",
    "    tf.summary.scalar('accuracy', accuracy)\n",
    "    tf.summary.scalar('cost', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe the input images in Tensorboard\n",
    "with tf.name_scope('show_image'):\n",
    "    x_image = tf.reshape(X, [-1, 28, 28, 1])\n",
    "    tf.summary.image('image_input', x_image, max_outputs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Model Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FileWriter and merge summaries\n",
    "merged_summary = tf.summary.merge_all()\n",
    "\n",
    "train_writer = tf.summary.FileWriter(directory + '/train')\n",
    "train_writer.add_graph(sess.graph)\n",
    "\n",
    "validation_writer = tf.summary.FileWriter(directory + '/validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize all the variables\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are batch training, divide up the training data\n",
    "size_of_batch = 1000\n",
    "\n",
    "num_examples = y_train_data.shape[0]\n",
    "nr_iterations = int(num_examples/size_of_batch)\n",
    "\n",
    "index_in_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(batch_size, data, labels):\n",
    "    \n",
    "    global num_examples\n",
    "    global index_in_epoch\n",
    "    \n",
    "    start = index_in_epoch\n",
    "    index_in_epoch += batch_size\n",
    "    \n",
    "    if index_in_epoch > num_examples:\n",
    "        start = 0\n",
    "        index_in_epoch = batch_size\n",
    "    \n",
    "    end = index_in_epoch\n",
    "    \n",
    "    return data[start:end], labels[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 \t| Training Accuracy = 0.6129999756813049\n",
      "Epoch 1 \t| Training Accuracy = 0.7490000128746033\n",
      "Epoch 2 \t| Training Accuracy = 0.8349999785423279\n",
      "Epoch 3 \t| Training Accuracy = 0.8420000076293945\n",
      "Epoch 4 \t| Training Accuracy = 0.8519999980926514\n",
      "Epoch 5 \t| Training Accuracy = 0.8679999709129333\n",
      "Epoch 6 \t| Training Accuracy = 0.8679999709129333\n",
      "Epoch 7 \t| Training Accuracy = 0.8730000257492065\n",
      "Epoch 8 \t| Training Accuracy = 0.871999979019165\n",
      "Epoch 9 \t| Training Accuracy = 0.8709999918937683\n",
      "Epoch 10 \t| Training Accuracy = 0.8759999871253967\n",
      "Epoch 11 \t| Training Accuracy = 0.8790000081062317\n",
      "Epoch 12 \t| Training Accuracy = 0.9300000071525574\n",
      "Epoch 13 \t| Training Accuracy = 0.9490000009536743\n",
      "Epoch 14 \t| Training Accuracy = 0.9610000252723694\n",
      "Epoch 15 \t| Training Accuracy = 0.9629999995231628\n",
      "Epoch 16 \t| Training Accuracy = 0.9589999914169312\n",
      "Epoch 17 \t| Training Accuracy = 0.9620000123977661\n",
      "Epoch 18 \t| Training Accuracy = 0.9639999866485596\n",
      "Epoch 19 \t| Training Accuracy = 0.9599999785423279\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(nr_iterations):\n",
    "        \n",
    "        batch_x, batch_y = next_batch(batch_size=size_of_batch, data=x_train_data, labels=y_train_data)\n",
    "        \n",
    "        feed_dictionary = {X:batch_x, Y:batch_y}\n",
    "        \n",
    "        sess.run(train_step, feed_dict=feed_dictionary)\n",
    "        \n",
    "    # Aggregate epoch summary and log these changes to the filewriter\n",
    "    s, batch_accuracy = sess.run(fetches=[merged_summary, accuracy], feed_dict=feed_dictionary)\n",
    "    \n",
    "    train_writer.add_summary(s, epoch)\n",
    "    \n",
    "    print(f'Epoch {epoch} \\t| Training Accuracy = {batch_accuracy}')\n",
    "    \n",
    "    # Epoch Validation \n",
    "    summary = sess.run(fetches=merged_summary, feed_dict={X:x_validate, Y:y_validate})\n",
    "    validation_writer.add_summary(summary, epoch)\n",
    "\n",
    "print('Done training!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = sess.run(fetches=accuracy, feed_dict={X:x_test_data, Y:y_test_data})\n",
    "print(f'Accuracy on test set is {test_accuracy:0.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Model Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in an image from all categories\n",
    "\n",
    "# Find the first MNIST image from each category\n",
    "digits_found = [True]*10\n",
    "x_samples = [[]]*10\n",
    "y_samples = [[]]*10\n",
    "\n",
    "for i, j in zip(x_test_data, y_test_data):\n",
    "    mnist_num = np.where(j==1)[0][0]\n",
    "    if(digits_found[mnist_num]):\n",
    "        x_samples[mnist_num] = i.reshape(28,28)\n",
    "        y_samples[mnist_num] = j\n",
    "        digits_found[mnist_num] = False\n",
    "    \n",
    "    # If we have found one of every mnist digit we break\n",
    "    if(digits_found.count(True) == 0): break\n",
    "\n",
    "pil_arr   = np.asarray(x_samples)\n",
    "pil_class = np.asarray(y_samples)\n",
    "\n",
    "# plot the digits\n",
    "plt.figure(figsize=[15, 5])\n",
    "for i, j in zip(pil_arr, pil_class):\n",
    "    digit = np.where(j == 1)[0][0]\n",
    "    \n",
    "    plt.subplot(1, 10, digit+1)\n",
    "    prediction = sess.run(fetches=tf.argmax(output, axis=1), feed_dict={X:[i.ravel()]})\n",
    "    \n",
    "    plt.title(f'Digit: {digit}')\n",
    "    plt.xlabel(f'Prediction {prediction}')\n",
    "    plt.xlim(0, i.shape[0])\n",
    "    plt.ylim(i.shape[1], 0)\n",
    "    im = Image.fromarray(np.uint8(cm.gist_earth(i)*255))\n",
    "    plt.imshow(im)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rest Model For the Next Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_writer.close()\n",
    "validation_writer.close()\n",
    "sess.close()\n",
    "tf.reset_default_graph()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
